1.
从日志采集到报表显示

数据　采集　清洗　分类　统计等



2.技术选型

采集 Flume Kafka

存贮　Mysql HDFS Hbase Redis Mongdb

计算：　hive spark flink

查询 presto impala


３.数据流程设计

3.1 业务数据： mysql　

3.2 埋点数据：　额外的不影响业务的数据 比如浏览　点击　评论　点赞　停留　收藏等

Flume = > Kafka => Flume => HDFS =>hive, spark,presto,mysql

4.框架版本选择

4.1 hadoop稳定版
hadoop 2.7.2
flume 1.7.0
kafka 0.11
hive 1.2.1
zookeeper 3.4
mysql 5.6
java 1.8
presto 0.189

4.2 CDH 5.12 稳定版
hadoop 2.6.0
spark 默认1.6 升级到2.4
flume 1.6.0
hive 1.1.0
sqoop 1.4.6
zookeeper 3.4.5

5.服务器选择

需求　日活用户１００万
每人一天平均　１００条

每条日志１ｋ

每天　１００００万条数据　
size =  10000w /1000/1000 = 100G

半年内不扩容

100G * 180天　＝　　18000G ，　１８Ｔ

保存３个副本　　18* 3 = 54T

预留　３０％空间　　＝　７７Ｔ

约　８Ｔ　＊　１０台　服务器

单台价格　
dell r710　３Ｗ　＊　１０台　３０Ｗ
======================

后期加硬盘单台加到　２０Ｔ
加服务器 单台　２０Ｔ





















